default_model: gpt-4o
max_threads: 4

optimizer_config:
  enable_optimizer: true
  sample_size: 5  
  validation_sample_size: 3  
  optimizer_model: gpt-4o

datasets:
  papers:
    type: file
    path: ./papers_dataset.json

operations:
  - name: extract_data_analysis
    type: map
    model: gpt-4o
    output:
      schema:
        SearchEngine: list[string]
        QuantificationMethod: list[string]
        NumberOfMissedCleavages: list[string]
        Experiment: list[string]
        FactorValue: list[string]
        NumberOfTechnicalReplicates: list[string]
        NumberOfSamples: list[string]
        BiologicalReplicate: list[string]
        TechnicalReplicate: list[string]
        PooledSample: list[string]
        SupplementaryFile: list[string]
        OutOfScope: list[string]
    prompt: |
      Extract data analysis and quantification information from this proteomics paper.
      
      Paper: {{ input.filename }}
      {% if input.methods %}Methods: {{ input.methods }}{% endif %}
      {% if input.supplementary_information %}Supplementary: {{ input.supplementary_information }}{% endif %}
      
      Extract ALL variations of:
      - SearchEngine: database search software (e.g., "Mascot", "SEQUEST", "MaxQuant", "Andromeda", "MS-GF+", "Comet")
      - QuantificationMethod: quantification approach (e.g., "LFQ", "label-free quantification", "TMT", "iTRAQ", "SILAC", "spectral counting")
      - NumberOfMissedCleavages: missed cleavage settings (e.g., "2", "2 missed cleavages", "up to 2")
      - Experiment: experiment type (e.g., "phosphoproteomics", "proteomics", "interactomics", "ubiquitinomics")
      - FactorValue: experimental factors (e.g., "treatment vs control", "time points", "dose levels")
      - NumberOfTechnicalReplicates: technical replicates (e.g., "duplicate", "triplicate", "2 technical replicates")
      - NumberOfSamples: sample count (e.g., "9 organs", "5 mice", "12 samples")
      - BiologicalReplicate: biological replicate IDs (e.g., "replicate 1", "BR1", "Rep1")
      - TechnicalReplicate: technical replicate IDs (e.g., "TR1", "injection replicate")
      - PooledSample: pooled sample info (e.g., "pooled sample", "pool of 3 samples")
      - SupplementaryFile: supplementary files (e.g., "Table S1", "Supplementary Data 1")
      - OutOfScope: clearly irrelevant information (rarely used)
      
      Extract BOTH full names AND abbreviations.
      Return JSON only, no markdown. Empty list if field not found.
    
    gleaning:
      num_rounds: 1
      validation_prompt: |
        Check if extraction missed: (1) search engine software (CRITICAL), (2) experiment type (CRITICAL), (3) quantification method, (4) common tools (MaxQuant, Mascot, LFQ, TMT).
        Return: {"passes_validation": true/false, "critical_omissions": [...], "next_round_instructions": "..."}
    
    validate:
      - 'len(output["Experiment"]) > 0'

  - name: unnest_search_engine
    type: unnest
    unnest_key: SearchEngine
    keep_empty: true

  - name: resolve_search_engine
    type: resolve
    blocking_keys:
      - SearchEngine
    blocking_threshold: 0.70
    comparison_model: gpt-4o-mini
    comparison_prompt: |
      Are these the same search engine?
      Engine 1: "{{ input1.SearchEngine }}"
      Engine 2: "{{ input2.SearchEngine }}"
      
      Equivalences: "MaxQuant"="MaxQuant version 1.6", "Mascot"="mascot", "PD"="Proteome Discoverer", "MS-GF+"="MSGF+"
      Different: MaxQuant≠Mascot, Sequest≠Mascot, MS-GF+≠Comet
      Return "True" if same software, "False" if different.
    
    embedding_model: text-embedding-3-small
    resolution_model: gpt-4o
    resolution_prompt: |
      Standardize these search engines (prefer standard name, proper capitalization, no version):
      {% for entry in inputs %}{{ entry.SearchEngine }}{% if not loop.last %}, {% endif %}{% endfor %}
      
      Examples: ["MaxQuant","MaxQuant v1.6","maxquant"]→"MaxQuant", ["SEQUEST","Sequest"]→"Sequest", ["PD","Proteome Discoverer"]→"Proteome Discoverer"
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_search_engine: string

  - name: unnest_quant_method
    type: unnest
    unnest_key: QuantificationMethod
    keep_empty: true

  - name: resolve_quant_method
    type: resolve
    blocking_keys:
      - QuantificationMethod
    blocking_threshold: 0.65
    comparison_model: gpt-4o-mini
    comparison_prompt: |
      Are these the same quantification method?
      Method 1: "{{ input1.QuantificationMethod }}"
      Method 2: "{{ input2.QuantificationMethod }}"
      
      Equivalences: "LFQ"="label-free quantification", "TMT"="tandem mass tag", "iTRAQ"="itraq", "SILAC"="stable isotope labeling", "spectral counting"="spectrum counting"
      Different: LFQ≠TMT, TMT≠iTRAQ, spectral counting≠intensity-based
      Return "True" if same method, "False" if different.
    
    embedding_model: text-embedding-3-small
    resolution_model: gpt-4o
    resolution_prompt: |
      Standardize these quantification methods (prefer full name with abbreviation):
      {% for entry in inputs %}{{ entry.QuantificationMethod }}{% if not loop.last %}, {% endif %}{% endfor %}
      
      Examples: ["LFQ","label-free"]→"label-free quantification (LFQ)", ["TMT","tandem mass tag"]→"tandem mass tag quantification (TMT)", ["spectral counting","spectrum counting"]→"spectral counting"
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_quant_method: string

  - name: unnest_experiment
    type: unnest
    unnest_key: Experiment
    keep_empty: true

  - name: resolve_experiment
    type: resolve
    blocking_keys:
      - Experiment
    blocking_threshold: 0.70
    comparison_model: gpt-4o-mini
    comparison_prompt: |
      Are these the same experiment type?
      Type 1: "{{ input1.Experiment }}"
      Type 2: "{{ input2.Experiment }}"
      
      Equivalences: "phosphoproteomics"="phospho-proteomics"="global phosphoproteomics", "proteomics"="global proteomics", "interactomics"="protein-protein interaction"
      Different: phosphoproteomics≠proteomics, interactomics≠proteomics
      Return "True" if same type, "False" if different.
    
    embedding_model: text-embedding-3-small
    resolution_model: gpt-4o
    resolution_prompt: |
      Standardize these experiment types (prefer standard terminology, no hyphens):
      {% for entry in inputs %}{{ entry.Experiment }}{% if not loop.last %}, {% endif %}{% endfor %}
      
      Examples: ["phosphoproteomics","phospho-proteomics"]→"phosphoproteomics", ["proteomics","global proteomics"]→"proteomics", ["TMT proteomics"]→"proteomics"
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_experiment: string

  - name: aggregate_data_analysis
    type: reduce
    reduce_key:
      - filename
    model: gpt-4o
    output:
      schema:
        unique_search_engines: list[string]
        unique_quant_methods: list[string]
        unique_experiments: list[string]
        missed_cleavages: list[string]
        factor_values: list[string]
        technical_replicates: list[string]
        number_of_samples: list[string]
        biological_replicates: list[string]
        technical_replicate_ids: list[string]
        pooled_samples: list[string]
        supplementary_files: list[string]
    prompt: |
      Aggregate and deduplicate data analysis info for: {{ reduce_key.filename }}
      
      {% for doc in inputs %}
      Search engine: {% if doc.canonical_search_engine %}{{ doc.canonical_search_engine }}{% endif %}
      Quantification: {% if doc.canonical_quant_method %}{{ doc.canonical_quant_method }}{% endif %}
      Experiment: {% if doc.canonical_experiment %}{{ doc.canonical_experiment }}{% endif %}
      Missed cleavages: {% for m in doc.NumberOfMissedCleavages %}{{ m }}, {% endfor %}
      Factors: {% for f in doc.FactorValue %}{{ f }}, {% endfor %}
      Tech replicates: {% for t in doc.NumberOfTechnicalReplicates %}{{ t }}, {% endfor %}
      Samples: {% for s in doc.NumberOfSamples %}{{ s }}, {% endfor %}
      {% endfor %}
      
      Return deduplicated JSON with unique canonical values for all fields.

pipeline:
  steps:
    - name: data_analysis_pipeline
      input: papers
      operations:
        - extract_data_analysis
        - unnest_search_engine
        - resolve_search_engine
        - unnest_quant_method
        - resolve_quant_method
        - unnest_experiment
        - resolve_experiment
        - aggregate_data_analysis

  output:
    type: file
    path: ./output/data_analysis_complete.json
    intermediate_dir: ./checkpoints