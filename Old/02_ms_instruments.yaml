default_model: gpt-4o
max_threads: 4

optimizer_config:
  enable_optimizer: true
  sample_size: 5  
  validation_sample_size: 3  
  optimizer_model: gpt-4o

datasets:
  papers:
    type: file
    path: ./papers_dataset.json

operations:
  - name: extract_ms_instruments
    type: map
    model: gpt-4o
    output:
      schema:
        Instrument: list[string]
        AcquisitionMethod: list[string]
        IonizationType: list[string]
        FragmentationMethod: list[string]
        MS2MassAnalyzer: list[string]
        CollisionEnergy: list[string]
        PrecursorMassTolerance: list[string]
        FragmentMassTolerance: list[string]
        TechnologyType: list[string]
    prompt: |
      Extract mass spectrometry instrumentation information from this proteomics paper.
      
      Paper: {{ input.filename }}
      {% if input.methods %}Methods: {{ input.methods }}{% endif %}
      {% if input.supplementary_information %}Supplementary: {{ input.supplementary_information }}{% endif %}
      
      Extract ALL variations of:
      - Instrument: full names AND abbreviations (e.g., "hybrid linear ion trap Orbitrap", "LTQ-Orbitrap Velos", "Thermo Scientific")
      - AcquisitionMethod: acquisition modes (e.g., "LC-MS/MS", "DDA", "data-dependent", "SWATH", "PRM")
      - IonizationType: ionization source (e.g., "ESI", "electrospray ionization", "MALDI", "nano-ESI")
      - FragmentationMethod: fragmentation techniques (e.g., "HCD", "higher-energy collisional dissociation", "CID", "ETD")
      - MS2MassAnalyzer: MS2 analyzer type (e.g., "Orbitrap", "ion trap", "TOF", "Q-TOF")
      - CollisionEnergy: collision energy (e.g., "28%", "NCE", "25-35%", "30 eV")
      - PrecursorMassTolerance: MS1 tolerance (e.g., "10 ppm", "20 ppm", "0.5 Da")
      - FragmentMassTolerance: MS2 tolerance (e.g., "0.02 Da", "0.6 Da", "20 ppm")
      - TechnologyType: MS technology (e.g., "LC-MS/MS", "shotgun proteomics", "targeted proteomics")
      
      Return JSON only, no markdown. Empty list if field not found.
    
    gleaning:
      num_rounds: 1
      validation_prompt: |
        Check if extraction missed: (1) instrument names, (2) acquisition methods, (3) instrument variations (full+abbreviation), (4) ionization type.
        Return: {"passes_validation": true/false, "critical_omissions": [...], "next_round_instructions": "..."}
    
    validate:
      - 'len(output["Instrument"]) > 0'
      - 'len(output["AcquisitionMethod"]) > 0'

  - name: unnest_instrument
    type: unnest
    unnest_key: Instrument
    keep_empty: false

  - name: resolve_instrument
    type: resolve
    blocking_keys:
      - Instrument
    blocking_threshold: 0.75
    comparison_model: gpt-4o-mini
    comparison_prompt: |
      Are these the same instrument?
      Instrument 1: "{{ input1.Instrument }}"
      Instrument 2: "{{ input2.Instrument }}"
      
      Equivalences: "Orbitrap"="Orbitrap Fusion", "LTQ-Orbitrap"="LTQ Orbitrap", "Thermo Scientific"="Thermo Fisher"
      Different: "Orbitrap"≠"Q-TOF", "Bruker"≠"Waters"
      Return "True" if same, "False" if different.
    
    embedding_model: text-embedding-3-small
    resolution_model: gpt-4o-mini
    resolution_prompt: |
      Standardize these instruments (prefer specific model):
      {% for entry in inputs %}{{ entry.Instrument }}{% if not loop.last %}, {% endif %}{% endfor %}
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_instrument: string

  - name: unnest_fragmentation
    type: unnest
    unnest_key: FragmentationMethod
    keep_empty: true

  - name: resolve_fragmentation
    type: resolve
    blocking_keys:
      - FragmentationMethod
    blocking_threshold: 0.85
    comparison_model: gpt-4o-mini
    comparison_prompt: |
      Are these the same fragmentation method?
      Method 1: "{{ input1.FragmentationMethod }}"
      Method 2: "{{ input2.FragmentationMethod }}"
      
      Equivalences: "HCD"="higher-energy collisional dissociation", "CID"="collision-induced dissociation", "ETD"="electron-transfer dissociation"
      Return "True" if same, "False" if different.
    
    embedding_model: text-embedding-3-small
    resolution_model: gpt-4o-mini
    resolution_prompt: |
      Standardize these fragmentation methods (prefer full form):
      {% for entry in inputs %}{{ entry.FragmentationMethod }}{% if not loop.last %}, {% endif %}{% endfor %}
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_fragmentation: string

  - name: aggregate_ms_info
    type: reduce
    reduce_key:
      - filename
    output:
      schema:
        unique_instruments: list[string]
        unique_acquisition_methods: list[string]
        unique_fragmentation_methods: list[string]
        unique_ionization_types: list[string]
        unique_ms2_analyzers: list[string]
        unique_technology_types: list[string]
    prompt: |
      Aggregate and deduplicate MS instrumentation for: {{ reduce_key.filename }}
      
      {% for doc in inputs %}
      Instruments: {% if doc.canonical_instrument %}{{ doc.canonical_instrument }}{% elif doc.Instrument %}{{ doc.Instrument }}{% endif %}
      Fragmentation: {% if doc.canonical_fragmentation %}{{ doc.canonical_fragmentation }}{% elif doc.FragmentationMethod %}{{ doc.FragmentationMethod }}{% endif %}
      Acquisition: {% for a in doc.AcquisitionMethod %}{{ a }}, {% endfor %}
      Ionization: {% for i in doc.IonizationType %}{{ i }}, {% endfor %}
      MS2 Analyzer: {% for m in doc.MS2MassAnalyzer %}{{ m }}, {% endfor %}
      Technology: {% for t in doc.TechnologyType %}{{ t }}, {% endfor %}
      {% endfor %}
      
      Return deduplicated JSON. Remove empty strings, nulls, and generic locations (e.g., "Sunnyvale", "CA"). Keep only actual MS instrument names, methods, and technologies.

pipeline:
  steps:
    - name: ms_pipeline
      input: papers
      operations:
        - extract_ms_instruments
        - unnest_instrument
        - resolve_instrument
        - unnest_fragmentation
        - resolve_fragmentation
        - aggregate_ms_info

  output:
    type: file
    path: ./output/ms_instruments_complete.json
    intermediate_dir: ./checkpoints