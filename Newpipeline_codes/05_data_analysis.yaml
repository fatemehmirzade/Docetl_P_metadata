default_model: gpt-4o
max_threads: 4

optimizer_config:
  enable_optimizer: true
  sample_size: 5  
  validation_sample_size: 3  
  optimizer_model: gpt-4o

datasets:
  papers:
    type: file
    path: ./papers_dataset.json

operations:
  - name: extract_data_analysis
    type: map
    model: gpt-4o
    output:
      schema:
        SearchEngine: list[string]
        QuantificationMethod: list[string]
        MissedCleavages: list[string]
        Experiment: list[string]
        FactorValue: list[string]
        NumberOfTechnicalReplicates: list[string]
        NumberOfSamples: list[string]
        BiologicalReplicate: list[string]
        TechnicalReplicate: list[string]
        PooledSample: list[string]
        SupplementaryFile: list[string]
        OutOfScope: list[string]
    prompt: |
      You are extracting data analysis and quantification metadata from proteomics research papers to enable standardized data cataloging, computational reproducibility, and statistical comparison across studies. Your task is to carefully read the provided text and identify all explicitly mentioned data analysis details across 12 categories. This information is critical for researchers to understand database search parameters, quantification strategies, experimental design (including replication structure), and to reproduce bioinformatics workflows that transform raw mass spectrometry data into biological insights.
      
      Paper: {{ input.filename }}
      {% if input.methods %}
      Methods section:
      """{{ input.methods }}"""
      {% endif %}
      {% if input.supplementary_information %}
      Supplementary information:
      """{{ input.supplementary_information }}"""
      {% endif %}
      
      Extract ALL mentions of the following categories. ONLY extract information that is explicitly stated in the text - do not infer, assume, or generate any information:
      
      - SearchEngine: database search, identification, and validation software (e.g., "Mascot", "SEQUEST", "Sequest", "Sequest HT", "MaxQuant", "Andromeda", "MS-GF+", "MS-GFDB", "Comet", "X!Tandem", "Proteome Discoverer", "PEAKS", "Percolator", "PeptideProphet", "ProteinProphet", "Morpheus", "MSFragger", "pFind", "Byonic", "ProteinPilot", "Ascore")
      
        Extract ALL software mentioned for:
        * Database searching: "Mascot", "SEQUEST", "Sequest", "Sequest HT", "Andromeda", "Comet", "X!Tandem", "MS-GF+", "MSFragger"
        * Workflow platforms: "MaxQuant", "Proteome Discoverer", "PD", "Skyline", "Scaffold"  
        * Statistical validation: "Percolator", "PeptideProphet", "ProteinProphet", "Peptide Prophet", "Protein Prophet", "Mascot Percolator", "Mascot Percolator V2"
        * Specialized tools: "Morpheus", "MSFragger", "pFind", "Byonic", "ProteinPilot", "Ascore"
        
        **IMPORTANT**: 
        - Check figure legends, supplementary materials, and data availability sections - software is often mentioned there
        - "Mascot Percolator" or "Mascot Percolator V2" → extract as "Mascot" AND "Percolator" separately
        - "X!Tandem", "X!TANDEM", "X-Tandem" → extract as "X!Tandem"
      
      - QuantificationMethod: protein/peptide quantification approaches (e.g., "LFQ", "label-free quantification", "TMT quantification", "iTRAQ quantification", "SILAC", "spectral counting", "peak intensity", "iBAQ", "intensity-based absolute quantification")
      - MissedCleavages: missed cleavage parameter settings (e.g., "2", "3", "2 missed cleavages allowed", "up to 2 missed cleavages", "maximum of 2", "3 missed cleavages")
        
        **IMPORTANT**: Extract just the number (e.g., "2", "3"), but also capture descriptive forms like "2 missed cleavages"
      
      - Experiment: experiment type or assay category (e.g., "phosphoproteomics", "global proteomics", "proteomics", "interactomics", "ubiquitinomics", "glycoproteomics", "secretome analysis", "affinity purification-mass spectrometry", "AP-MS")
      
        **INFERENCE ALLOWED FOR EXPERIMENT TYPE ONLY**: If experiment type is not explicitly stated, you may carefully infer it from context:
        * Paper extensively discusses "phosphorylation" + has phospho-enrichment → "phosphoproteomics"
        * Paper discusses "ubiquitin" + has ubiquitin enrichment → "ubiquitinomics"  
        * Paper describes immunoprecipitation + mass spec → "interactomics" or "affinity purification-mass spectrometry"
        * Paper describes glycan analysis → "glycoproteomics"
        * No specialized PTM focus + broad protein coverage → "proteomics" or "global proteomics"
        
        When inferring, be conservative and choose the most general applicable term. This is the ONLY category where inference is explicitly permitted.
      - FactorValue: experimental factors or conditions being compared (e.g., "treatment vs control", "wild-type vs knockout", "time points: 0h, 6h, 24h", "dose: low, medium, high", "disease vs healthy")
      - NumberOfTechnicalReplicates: technical replicate counts (e.g., "duplicate", "triplicate", "2 technical replicates", "3 injections per sample")
      - NumberOfSamples: total sample count or per-group counts (e.g., "9 organs", "5 mice per group", "12 samples total", "n=8 per condition")
      - BiologicalReplicate: biological replicate identifiers or descriptions (e.g., "biological replicate 1", "BR1", "Rep1", "three biological replicates")
      - TechnicalReplicate: technical replicate identifiers (e.g., "TR1", "technical replicate A", "injection replicate 1")
      - PooledSample: pooled or reference sample information (e.g., "pooled sample", "pool of 3 samples", "reference channel", "common reference pool")
      - SupplementaryFile: supplementary data file references (e.g., "Table S1", "Supplementary Data 1", "Supplementary Table 2", "Dataset S1")
      - OutOfScope: information clearly not relevant to proteomics metadata (rarely used - only for obviously irrelevant content)
      
      IMPORTANT INSTRUCTIONS:
      - Extract information EXACTLY as written in the text
      - Capture BOTH full software names AND abbreviations when present (e.g., both "MaxQuant" and "MaxQuant version 1.6.10.43")
      - Capture BOTH full method names AND abbreviations (e.g., both "LFQ" and "label-free quantification")
      - For MissedCleavages: extract the number value (e.g., "2", "3") but also capture descriptive forms
      - If you are uncertain whether information belongs to a category, do NOT include it
      - If a category has no explicitly mentioned information, return an empty list for that category
      - Do not make assumptions or inferences beyond what is directly stated (except for Experiment type)
      - For search engines, capture software name but do not focus on version numbers (these can vary)
      - For experiment types, capture the primary proteomics approach described
      - For replicates and samples, extract exact counts when mentioned
      
      Return your response as valid JSON using the category names above as keys, with lists of extracted strings as values. Do not include markdown formatting, code blocks, or any text outside the JSON structure. Return only the JSON object.
    
    gleaning:
      num_rounds: 2
      validation_prompt: |
        DATA ANALYSIS VALIDATION with search engine priority:
        
        1. **Search engine software** (CRITICAL - present in 99%+ of papers):
           - Was search engine extracted? This is MANDATORY.
           - Common search engines: "MaxQuant", "Mascot", "SEQUEST", "Sequest HT", "Andromeda", "Proteome Discoverer", "Comet", "MS-GF+", "Morpheus", "MSFragger"
           - Common validation tools: "Percolator", "PeptideProphet", "ProteinProphet"
           - Check phrases: "analyzed using", "searched with", "identified using", "processed with", "analyzed with", "searched against"
           - Check different sections:
             * Methods: "Data Analysis", "Database Searching", "Protein Identification"
             * Figure legends: often mentions software
             * Supplementary: "Mass Spectrometry Data Analysis"
             * Data availability: software versions listed
        
        2. **Experiment type** (CRITICAL - defines study approach):
           - Was experiment type extracted?
           - Look for explicit mentions: "phosphoproteomics", "proteomics", "interactomics", "ubiquitinomics"
           - If not explicit, check context for inference:
             * Multiple mentions of "phosphorylation" + enrichment → infer "phosphoproteomics"
             * Immunoprecipitation + MS → infer "interactomics" or "affinity purification-mass spectrometry"
             * Broad protein coverage, no PTM focus → infer "proteomics" or "global proteomics"
           - Check paper title and abstract if methods section unclear
        
        3. **Quantification method** (important for data interpretation):
           - Look for: "LFQ", "label-free", "label-free quantification", "TMT", "iTRAQ", "SILAC", "spectral counting"
           - Phrases: "quantified using", "quantification was performed", "relative quantification"
           - Often same sentence as software mention: "MaxQuant with LFQ", "Proteome Discoverer with TMT quantification"
        
        4. **Technical replicates** (important for reproducibility):
           - Look for: "duplicate", "triplicate", "2 technical replicates", "3 injections", "samples were analyzed in duplicate"
           - Check methods and figure legends
        
        5. **Common software combinations** to check:
           - MaxQuant almost always mentioned with "Andromeda" (its search engine)
           - Proteome Discoverer often with "Sequest HT" or "Mascot"
           - Percolator often used with "Comet" or other search engines for validation
           - If you see workflow platform (MaxQuant, PD), check for underlying search engine
        
        6. **Software in unexpected places**:
           - Figure legends: "Protein identification was performed using MaxQuant"
           - Supplementary methods: detailed parameter descriptions
           - Data availability: "MS data were processed using Proteome Discoverer 2.4"
        
        Common extraction errors:
        - Search engine mentioned in supplementary but not extracted (MOST COMMON)
        - Validation software (Percolator) mentioned but not extracted
        - Software mentioned in figure legends but missed
        - Experiment type only implied, not extracted
        - Quantification method described generically (e.g., "label-free") without specific approach
        - Technical replicates mentioned but not extracted
        
        Return JSON with detailed findings:
        {
          "passes_validation": true or false (false if search engine or experiment type missing),
          "missing_search_engine": true or false (CRITICAL if true),
          "search_engine_hints": [phrases that suggest software, e.g., "analyzed using", "searched with"],
          "missing_experiment_type": true or false (CRITICAL if true),
          "experiment_type_inference": "suggested type based on context" (if not explicit),
          "missing_quantification": true or false,
          "missing_technical_replicates": true or false,
          "missing_validation_software": true or false (e.g., Percolator),
          "check_supplementary": true or false (should look in supp materials),
          "check_figure_legends": true or false (should look in figures),
          "critical_omissions": [specific quotes showing missed software mentions],
          "next_round_instructions": "Priority: Search for [specific software type] in [specific sections]"
        }
    
    validate:
      - 'len(output["Experiment"]) > 0'

  - name: unnest_search_engine
    type: unnest
    unnest_key: SearchEngine
    keep_empty: true

  - name: resolve_search_engine
    type: resolve
    blocking_keys:
      - SearchEngine
    blocking_threshold: 0.70
    embedding_model: text-embedding-3-small
    embedding_threshold: 0.88
    comparison_prompt: |
      Are these the same search engine?
      Engine 1: "{{ input1.SearchEngine }}"
      Engine 2: "{{ input2.SearchEngine }}"
      Return "True" if same, "False" if different.
    resolution_model: gpt-4o
    resolution_prompt: |
      Standardize these search engines (prefer standard name, proper capitalization, no version):
      {% for entry in inputs %}{{ entry.SearchEngine }}{% if not loop.last %}, {% endif %}{% endfor %}
      
      Examples: ["MaxQuant","MaxQuant v1.6","maxquant"]→"MaxQuant", ["SEQUEST","Sequest"]→"Sequest", ["PD","Proteome Discoverer"]→"Proteome Discoverer"
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_search_engine: string

  - name: unnest_quant_method
    type: unnest
    unnest_key: QuantificationMethod
    keep_empty: true

  - name: resolve_quant_method
    type: resolve
    blocking_keys:
      - QuantificationMethod
    blocking_threshold: 0.65
    embedding_model: text-embedding-3-small
    embedding_threshold: 0.88
    comparison_prompt: |
      Are these the same quant method?
      Method 1: "{{ input1.QuantificationMethod }}"
      Method 2: "{{ input2.QuantificationMethod }}"
      Return "True" if same, "False" if different.
    resolution_model: gpt-4o
    resolution_prompt: |
      Standardize these quantification methods (prefer full name with abbreviation):
      {% for entry in inputs %}{{ entry.QuantificationMethod }}{% if not loop.last %}, {% endif %}{% endfor %}
      
      Examples: ["LFQ","label-free"]→"label-free quantification (LFQ)", ["TMT","tandem mass tag"]→"tandem mass tag quantification (TMT)", ["spectral counting","spectrum counting"]→"spectral counting"
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_quant_method: string

  - name: unnest_experiment
    type: unnest
    unnest_key: Experiment
    keep_empty: true

  - name: resolve_experiment
    type: resolve
    blocking_keys:
      - Experiment
    blocking_threshold: 0.70
    embedding_model: text-embedding-3-small
    embedding_threshold: 0.88
    comparison_prompt: |
      Are these the same experiment?
      Type 1: "{{ input1.Experiment }}"
      Type 2: "{{ input2.Experiment }}"
      Return "True" if same, "False" if different.
    resolution_model: gpt-4o
    resolution_prompt: |
      Standardize these experiment types (prefer standard terminology, no hyphens):
      {% for entry in inputs %}{{ entry.Experiment }}{% if not loop.last %}, {% endif %}{% endfor %}
      
      Examples: ["phosphoproteomics","phospho-proteomics"]→"phosphoproteomics", ["proteomics","global proteomics"]→"proteomics", ["TMT proteomics"]→"proteomics"
      Return ONLY the canonical name.
    
    output:
      schema:
        canonical_experiment: string

  - name: aggregate_data_analysis
    type: reduce
    reduce_key:
      - filename
    optimize: true
    model: gpt-4o
    output:
      schema:
        unique_search_engines: list[string]
        unique_quant_methods: list[string]
        unique_experiments: list[string]
        missed_cleavages: list[string]
        factor_values: list[string]
        technical_replicates: list[string]
        number_of_samples: list[string]
        biological_replicates: list[string]
        technical_replicate_ids: list[string]
        pooled_samples: list[string]
        supplementary_files: list[string]
    prompt: |
      Aggregate and deduplicate data analysis info for: {{ reduce_key.filename }}
      
      {% for doc in inputs %}
      Search engine: {% if doc.canonical_search_engine %}{{ doc.canonical_search_engine }}{% endif %}
      Quantification: {% if doc.canonical_quant_method %}{{ doc.canonical_quant_method }}{% endif %}
      Experiment: {% if doc.canonical_experiment %}{{ doc.canonical_experiment }}{% endif %}
      Missed cleavages: {% for m in doc.MissedCleavages %}{{ m }}, {% endfor %}
      Factors: {% for f in doc.FactorValue %}{{ f }}, {% endfor %}
      Tech replicates: {% for t in doc.NumberOfTechnicalReplicates %}{{ t }}, {% endfor %}
      Samples: {% for s in doc.NumberOfSamples %}{{ s }}, {% endfor %}
      {% endfor %}
      
      Return deduplicated JSON with unique canonical values for all fields.

pipeline:
  steps:
    - name: data_analysis_pipeline
      input: papers
      operations:
        - extract_data_analysis
        - unnest_search_engine
        - resolve_search_engine
        - unnest_quant_method
        - resolve_quant_method
        - unnest_experiment
        - resolve_experiment
        - aggregate_data_analysis

  output:
    type: file
    path: ./output/data_analysis_complete.json
    intermediate_dir: ./checkpoints